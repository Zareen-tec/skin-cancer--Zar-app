# -*- coding: utf-8 -*-
"""final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QGtXlKwkLftyFhlqVlO0SNx4xsA7ko1w
"""

# Install necessary packages
!pip install pyngrok streamlit

import os
import cv2
import numpy as np
from sklearn.model_selection import train_test_split
from keras.applications import MobileNetV2
from keras import layers, models
from google.colab import drive
from pyngrok import ngrok
import streamlit as st
from PIL import Image
import threading

# Set your ngrok authtoken (VERY IMPORTANT)
ngrok.set_auth_token("2wLyUiEuliGlvsNtGoNyaELsc5g_3SGeKVXQbzP7dNDvZLJZC")  # <-- PUT YOUR TOKEN HERE

# 1. Mount Google Drive
drive.mount('/content/drive')

# 2. Define Paths
dataset_path = "/content/drive/My Drive/dataset"
train_folder = "/content/drive/My Drive/pro_dataset/train"
test_folder = "/content/drive/My Drive/pro_dataset/test"

# Create folders if they don't exist
os.makedirs(train_folder, exist_ok=True)
os.makedirs(test_folder, exist_ok=True)

# 3. Load images and assign labels
def load_images_and_labels(dataset_path, limit=500):
    images, filenames, labels = [], [], []
    image_files = []

    for root, _, files in os.walk(dataset_path):
        for file in files:
            if file.endswith((".jpg", ".png", ".jpeg")):
                image_files.append(os.path.join(root, file))
            if len(image_files) >= limit:
                break
        if len(image_files) >= limit:
            break

    print(f"Found {len(image_files)} images. Loading...")

    for file_path in image_files:
        img = cv2.imread(file_path)
        if img is not None:
            images.append(img)
            filenames.append(os.path.basename(file_path))
            label = 1 if "melanoma" in file_path.lower() else 0
            labels.append(label)

    if len(images) == 0:
        raise ValueError("No images found! Check dataset path.")

    return images, filenames, np.array(labels)

# 4. Preprocess images
def preprocess_images(images):
    processed_images = []
    for img in images:
        img_resized = cv2.resize(img, (224, 224))
        img_normalized = img_resized / 255.0
        processed_images.append(img_normalized)
    return np.array(processed_images)

# 5. Split and save dataset
def split_and_save_dataset(X, y, filenames, test_size=0.2):
    X_train, X_test, y_train, y_test, train_filenames, test_filenames = train_test_split(
        X, y, filenames, test_size=test_size, random_state=42
    )

    for img, name in zip(X_train, train_filenames):
        cv2.imwrite(os.path.join(train_folder, name), (img * 255).astype(np.uint8))
    for img, name in zip(X_test, test_filenames):
        cv2.imwrite(os.path.join(test_folder, name), (img * 255).astype(np.uint8))

    return X_train, X_test, y_train, y_test

# 6. Load and preprocess
images, filenames, labels = load_images_and_labels(dataset_path, limit=500)
processed_images = preprocess_images(images)
X_train, X_test, y_train, y_test = split_and_save_dataset(processed_images, labels, filenames)

# 7. Model: MobileNetV2
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False

model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# 8. Train the model
history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=15,
    batch_size=32
)

# 9. Save the trained model
model.save("/content/skin_cancer_model.h5")
print("âœ… Model saved successfully!")

# 10. Streamlit App Interface
def streamlit_interface():
    st.title("ðŸ§ª Skin Cancer Detection (Upload Image)")

    uploaded_image = st.file_uploader("Upload a skin image...", type=["jpg", "png", "jpeg"])

    if uploaded_image is not None:
        img = Image.open(uploaded_image)
        st.image(img, caption="Uploaded Image", use_column_width=True)

        img_resized = img.resize((224, 224))
        img_array = np.array(img_resized) / 255.0
        img_input = np.expand_dims(img_array, axis=0)

        prediction = model.predict(img_input)
        result = "melanoma" if prediction[0][0] > 0.5 else "Non-melanoma"

        st.subheader(f"Prediction: {result}")

# 11. Launch Streamlit App properly in Colab
def run_streamlit():
    !streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py --server.port 8501

thread = threading.Thread(target=run_streamlit)
thread.start()

# Expose using ngrok
public_url = ngrok.connect(addr="http://localhost:8501", proto="http")

print(f"ðŸš€ Your app is live at: {public_url}")